{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQAcyu-Ur2B0",
        "outputId": "da54a282-1575-4fa5-b8f4-2baadbed6347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') \n",
        "diabetes = '/content/gdrive/My Drive/diabetes.csv'\n",
        "bc = '/content/gdrive/My Drive/breastcancer.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kqEccxQeqg9z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ICP Part 1\n",
        "\n",
        "Using the diabetes dataset"
      ],
      "metadata": {
        "id": "hiWoMTzhxCq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Diabetes dataset\n",
        "dataset = pd.read_csv(diabetes, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "#Adding 3 additional dense layers to see how accuracy changes\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # additional hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # additional hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # additional hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDvMMay4tCbz",
        "outputId": "e807ac7d-99b4-4c99-a322-a11a6e8a85de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 2ms/step - loss: 4.4076 - acc: 0.4253\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.4218 - acc: 0.4149\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9696 - acc: 0.4861\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7786 - acc: 0.5208\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6905 - acc: 0.6285\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6513 - acc: 0.6684\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6242 - acc: 0.6632\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6187 - acc: 0.6649\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6014 - acc: 0.6962\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5991 - acc: 0.6788\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6135 - acc: 0.6823\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5853 - acc: 0.6979\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5889 - acc: 0.6788\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5894 - acc: 0.6979\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5863 - acc: 0.7049\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6000 - acc: 0.6910\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5751 - acc: 0.7101\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5651 - acc: 0.7083\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5613 - acc: 0.7153\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5663 - acc: 0.6910\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5752 - acc: 0.7049\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - acc: 0.7101\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5705 - acc: 0.7153\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5615 - acc: 0.7222\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5564 - acc: 0.7274\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5712 - acc: 0.7292\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5501 - acc: 0.7188\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5697 - acc: 0.6892\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - acc: 0.6806\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5848 - acc: 0.7066\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5594 - acc: 0.7222\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5617 - acc: 0.7118\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5625 - acc: 0.6858\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - acc: 0.7066\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5448 - acc: 0.7101\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5481 - acc: 0.7240\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - acc: 0.7205\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - acc: 0.7257\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - acc: 0.7326\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5390 - acc: 0.7240\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - acc: 0.7257\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - acc: 0.7274\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5479 - acc: 0.7153\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5267 - acc: 0.7378\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - acc: 0.7309\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - acc: 0.7344\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - acc: 0.7413\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5257 - acc: 0.7274\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - acc: 0.7465\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5224 - acc: 0.7517\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - acc: 0.7240\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - acc: 0.7587\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - acc: 0.7465\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - acc: 0.7101\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - acc: 0.7361\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5112 - acc: 0.7465\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - acc: 0.7344\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5184 - acc: 0.7378\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5474 - acc: 0.7066\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - acc: 0.7326\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - acc: 0.7465\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - acc: 0.7361\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - acc: 0.7431\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - acc: 0.7361\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - acc: 0.7517\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5211 - acc: 0.7344\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5206 - acc: 0.7292\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - acc: 0.7413\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - acc: 0.7378\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - acc: 0.7500\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - acc: 0.7465\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - acc: 0.7535\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - acc: 0.7552\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - acc: 0.7413\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - acc: 0.7622\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5506 - acc: 0.7118\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - acc: 0.7066\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - acc: 0.7517\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - acc: 0.7465\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - acc: 0.7448\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - acc: 0.7569\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - acc: 0.7500\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - acc: 0.7569\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5230 - acc: 0.7257\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - acc: 0.7795\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - acc: 0.7483\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - acc: 0.7552\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - acc: 0.7500\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - acc: 0.7396\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - acc: 0.7431\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - acc: 0.7726\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5016 - acc: 0.7535\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - acc: 0.7500\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - acc: 0.7448\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - acc: 0.7656\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - acc: 0.7674\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - acc: 0.7587\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - acc: 0.7743\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - acc: 0.7517\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - acc: 0.7622\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_38 (Dense)            (None, 20)                180       \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,461\n",
            "Trainable params: 1,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.5373 - acc: 0.7240\n",
            "[0.5373272895812988, 0.7239583134651184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy with only 1 dense layer: ~0.6771\n",
        "\n",
        "Accuracy with 3 dense layers: ~0.7240\n",
        "\n",
        "Adding the additional dense layers improved the accuracy ~5% which seems to be a efficient increase with only 3 extra lines of code."
      ],
      "metadata": {
        "id": "jlE1uj5PxMB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the breast cancer dataset"
      ],
      "metadata": {
        "id": "tv20VjfHxBga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(bc)\n",
        "dataset = dataset.drop(columns = ['id','Unnamed: 32'])\n",
        "dataset['diagnosis'] = dataset['diagnosis'].map({'M': 1, 'B': 0})\n",
        "data = dataset.values"
      ],
      "metadata": {
        "id": "HdkeUWjyyzar"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Breast Cancer dataset\n",
        "#dataset = pd.read_csv(bc).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data[:,1:31], data[:,0],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "#Adding 3 additional dense layers to see how accuracy changes\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # additional hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # additional hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # additional hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeTcXscRx90y",
        "outputId": "796fec5a-baf2-47dc-a0fe-f233b90c6295"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 19.1218 - acc: 0.4249\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 8.7200 - acc: 0.3709\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 5.0494 - acc: 0.4601\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.2647 - acc: 0.5376\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.8119 - acc: 0.7183\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3614 - acc: 0.8779\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2349 - acc: 0.9178\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2206 - acc: 0.9225\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2183 - acc: 0.9225\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2782 - acc: 0.8850\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2765 - acc: 0.8873\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2636 - acc: 0.9014\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1908 - acc: 0.9272\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2038 - acc: 0.9319\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2001 - acc: 0.9178\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2706 - acc: 0.8873\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2337 - acc: 0.9225\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2017 - acc: 0.9249\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2720 - acc: 0.8944\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2151 - acc: 0.9178\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2328 - acc: 0.9225\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1900 - acc: 0.9343\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1827 - acc: 0.9272\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2657 - acc: 0.9108\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2493 - acc: 0.9085\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2079 - acc: 0.9249\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1940 - acc: 0.9319\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1795 - acc: 0.9272\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1851 - acc: 0.9343\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1835 - acc: 0.9296\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2111 - acc: 0.9296\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1992 - acc: 0.9296\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2283 - acc: 0.9272\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1746 - acc: 0.9390\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2053 - acc: 0.9319\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2161 - acc: 0.9225\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1976 - acc: 0.9202\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2156 - acc: 0.9319\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2006 - acc: 0.9225\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1869 - acc: 0.9319\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2168 - acc: 0.9225\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2175 - acc: 0.9249\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2669 - acc: 0.9061\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1837 - acc: 0.9272\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1955 - acc: 0.9343\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2237 - acc: 0.9343\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1721 - acc: 0.9390\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1825 - acc: 0.9319\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2033 - acc: 0.9484\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2757 - acc: 0.8967\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1887 - acc: 0.9272\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1956 - acc: 0.9319\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2474 - acc: 0.9249\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1844 - acc: 0.9390\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1893 - acc: 0.9366\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1696 - acc: 0.9437\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1854 - acc: 0.9343\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1868 - acc: 0.9366\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1765 - acc: 0.9437\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1758 - acc: 0.9390\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1892 - acc: 0.9296\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2033 - acc: 0.9343\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1654 - acc: 0.9390\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1702 - acc: 0.9390\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1878 - acc: 0.9272\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1635 - acc: 0.9390\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1604 - acc: 0.9390\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1827 - acc: 0.9366\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1660 - acc: 0.9413\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1675 - acc: 0.9343\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1828 - acc: 0.9272\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3269 - acc: 0.8991\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3206 - acc: 0.8991\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1731 - acc: 0.9225\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1682 - acc: 0.9390\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1646 - acc: 0.9413\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9413\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1662 - acc: 0.9319\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1638 - acc: 0.9366\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1708 - acc: 0.9272\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1718 - acc: 0.9272\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1678 - acc: 0.9366\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1563 - acc: 0.9296\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1553 - acc: 0.9343\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1672 - acc: 0.9366\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2929 - acc: 0.8967\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2397 - acc: 0.9202\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1910 - acc: 0.9390\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1671 - acc: 0.9366\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1693 - acc: 0.9343\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1609 - acc: 0.9390\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2577 - acc: 0.9085\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1898 - acc: 0.9202\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1779 - acc: 0.9249\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1638 - acc: 0.9343\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1519 - acc: 0.9437\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2217 - acc: 0.9272\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1723 - acc: 0.9343\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2486 - acc: 0.9038\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1732 - acc: 0.9343\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901\n",
            "Trainable params: 1,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3066 - acc: 0.8741\n",
            "[0.306610643863678, 0.8741258978843689]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model that includes 4 dense layers had an accuracy ~0.8741"
      ],
      "metadata": {
        "id": "k79k0jR2vLP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the data using StandardScaler"
      ],
      "metadata": {
        "id": "oLR35em5vW3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "#Fitting the scaler using only the training data\n",
        "X_train = sc.fit_transform(X_train)\n",
        "#Transforming the testing data using the scaler that was fitted on the training data\n",
        "X_test = sc.transform (X_test)\n",
        "\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "#Adding 3 additional dense layers to see how accuracy changes\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # additional hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # additional hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # additional hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "id": "s8HNWZ9Xy_Fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b259f02a-aba2-4dab-d5ef-6f287949ac96"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.5856 - acc: 0.7958\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4443 - acc: 0.9155\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3071 - acc: 0.9437\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2066 - acc: 0.9531\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1495 - acc: 0.9624\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1189 - acc: 0.9671\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0969 - acc: 0.9695\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0815 - acc: 0.9742\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0716 - acc: 0.9765\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0628 - acc: 0.9836\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0561 - acc: 0.9836\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0513 - acc: 0.9883\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0467 - acc: 0.9883\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0426 - acc: 0.9906\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0385 - acc: 0.9906\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0351 - acc: 0.9906\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0330 - acc: 0.9930\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0297 - acc: 0.9930\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0271 - acc: 0.9906\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0263 - acc: 0.9930\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0225 - acc: 0.9930\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - acc: 0.9906\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0181 - acc: 0.9953\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0167 - acc: 0.9977\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0155 - acc: 0.9977\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0137 - acc: 0.9977\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - acc: 0.9977\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0118 - acc: 0.9977\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0110 - acc: 0.9977\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0104 - acc: 0.9977\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 0.9977\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0080 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0061 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 9.1030e-04 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 8.5847e-04 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 8.4431e-04 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 7.8127e-04 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 7.4275e-04 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 6.8898e-04 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 6.6523e-04 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 6.4138e-04 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 6.0199e-04 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 5.7184e-04 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 5.6531e-04 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 5.2190e-04 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 5.0845e-04 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 5.0128e-04 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 4.7529e-04 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 4.3554e-04 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 4.1586e-04 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 4.1066e-04 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 3.8809e-04 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 3.7620e-04 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 3.5579e-04 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 3.4602e-04 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 3.3244e-04 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 3.1840e-04 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 3.0910e-04 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.9960e-04 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.9142e-04 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.8001e-04 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.7433e-04 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.6488e-04 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.5445e-04 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.4728e-04 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.3821e-04 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.3058e-04 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.2319e-04 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.1891e-04 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.1393e-04 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 2.0568e-04 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 1.9887e-04 - acc: 1.0000\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_35 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901\n",
            "Trainable params: 1,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4486 - acc: 0.9650\n",
            "[0.4486065208911896, 0.9650349617004395]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the data using StandardScaler seems to have helped with the accuracy of the model tremendously. This can be seen because the variables used in the model have different ranges/magnitude and variance so scaling/normalizing them to be on the same 'scale' helps to reduce the variety of ranges and variance among the variables. This technique can help to alleviate the effect that outliers present in the data have on the training process of the model."
      ],
      "metadata": {
        "id": "PtNxq6Mqw88c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ICP Part 2:\n",
        "\n",
        "MNIST digits dataset"
      ],
      "metadata": {
        "id": "ZZSKMerMyAH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9G211UNx_iM",
        "outputId": "98d1d68f-e883-43d7-bd01-1af5a3373dd2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.2909 - accuracy: 0.9097 - val_loss: 0.1206 - val_accuracy: 0.9606\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.1008 - accuracy: 0.9693 - val_loss: 0.1136 - val_accuracy: 0.9618\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0644 - accuracy: 0.9801 - val_loss: 0.1093 - val_accuracy: 0.9667\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.0624 - val_accuracy: 0.9795\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.1041 - val_accuracy: 0.9665\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0598 - val_accuracy: 0.9812\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0730 - val_accuracy: 0.9794\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0611 - val_accuracy: 0.9838\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0727 - val_accuracy: 0.9818\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0627 - val_accuracy: 0.9847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting training & validation loss and accuracy"
      ],
      "metadata": {
        "id": "L7wZ5Yv60U-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (15,7))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.ylabel('Loss', fontsize = 16)\n",
        "plt.plot(history.history['loss'], label = 'Training Loss')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
        "plt.legend(loc = 'upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize = 16)\n",
        "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.legend(loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "jDh62I53zpQl",
        "outputId": "6067e21f-a1b8-463e-c68b-9c4a3b4d17ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss graph may be showing signs of overfitting because of the training loss going towards zero while the validation loss is not steadily decreasing, training with more epochs would likely help answer that question.\n",
        "\n",
        "The accuracy graph also shows that there may be some slight overfitting because of the gap between the training and validation curves."
      ],
      "metadata": {
        "id": "pAD1a7RZ-eFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting & predicting an image with the model"
      ],
      "metadata": {
        "id": "_vxiJNa60xaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_data[1].reshape(28,28), cmap='gray')\n",
        "plt.show()\n",
        "pred = model.predict(test_data[1].reshape(1,784))\n",
        "print(pred.argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "iSxuX_Gl0002",
        "outputId": "3c85b2a4-eb67-4091-84b3-6ca58585afd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model predicted the number to be a 2 and it was correct as you can see on the above plot."
      ],
      "metadata": {
        "id": "vddqrA4w6RcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding hidden layers & changing activation function"
      ],
      "metadata": {
        "id": "4WytTaR56YNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "#Adding 3 hidden layers and changing from relu to tanh\n",
        "model2.add(Dense(512, activation='tanh', input_shape=(dimData,)))\n",
        "model2.add(Dense(512, activation='tanh'))\n",
        "model2.add(Dense(512, activation='tanh'))\n",
        "model2.add(Dense(512, activation='tanh'))\n",
        "model2.add(Dense(512, activation='tanh'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model2.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U7vLxvH6Q4O",
        "outputId": "e042d075-cae2-40bf-92e5-11002235289f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 0.5124 - accuracy: 0.8533 - val_loss: 0.2828 - val_accuracy: 0.9105\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.1749 - accuracy: 0.9470 - val_loss: 0.1760 - val_accuracy: 0.9458\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.1125 - accuracy: 0.9654 - val_loss: 0.2095 - val_accuracy: 0.9395\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.1334 - val_accuracy: 0.9588\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 0.0603 - accuracy: 0.9804 - val_loss: 0.1093 - val_accuracy: 0.9686\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.0452 - accuracy: 0.9856 - val_loss: 0.1976 - val_accuracy: 0.9489\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.0984 - val_accuracy: 0.9722\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0722 - val_accuracy: 0.9781\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.1061 - val_accuracy: 0.9734\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0813 - val_accuracy: 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I added 3 more hidden layers and changed all of the activation functions to tanh instead of ReLu, the validation loss and accuracy did not change much, but the model using less hidden layers and the ReLu activation function seemed to perform slightly better."
      ],
      "metadata": {
        "id": "-rOSpkzo66__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training without scaling the images on original model"
      ],
      "metadata": {
        "id": "DA8SBsbv6gZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "#Using images that are not scaled with the original model\n",
        "\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model3.add(Dense(512, activation='relu'))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model3.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45sNrj6P3f7i",
        "outputId": "513cf509-cf6d-42d7-cdc5-2406d5460e75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 5.7078 - accuracy: 0.8764 - val_loss: 1.7800 - val_accuracy: 0.8496\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.4069 - accuracy: 0.9467 - val_loss: 0.4734 - val_accuracy: 0.9343\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2462 - accuracy: 0.9589 - val_loss: 0.3291 - val_accuracy: 0.9458\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.1937 - accuracy: 0.9668 - val_loss: 0.2498 - val_accuracy: 0.9590\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.1611 - accuracy: 0.9715 - val_loss: 0.3093 - val_accuracy: 0.9590\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1520 - accuracy: 0.9758 - val_loss: 0.2876 - val_accuracy: 0.9636\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.1335 - accuracy: 0.9789 - val_loss: 0.2770 - val_accuracy: 0.9690\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.1214 - accuracy: 0.9812 - val_loss: 0.3039 - val_accuracy: 0.9668\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1203 - accuracy: 0.9829 - val_loss: 0.3258 - val_accuracy: 0.9698\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.1140 - accuracy: 0.9843 - val_loss: 0.5022 - val_accuracy: 0.9565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training without scaling the images on model from part 3"
      ],
      "metadata": {
        "id": "73CXW_gs8Zb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential()\n",
        "#Using images that are not scaled\n",
        "#Added 3 more hidden layers and changed activation function to tanh\n",
        "model4.add(Dense(512, activation='tanh', input_shape=(dimData,)))\n",
        "model4.add(Dense(512, activation='tanh'))\n",
        "model4.add(Dense(512, activation='tanh'))\n",
        "model4.add(Dense(512, activation='tanh'))\n",
        "model4.add(Dense(512, activation='tanh'))\n",
        "model4.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model4.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwwr_NLh8tgl",
        "outputId": "da93264c-a820-472f-92f7-0cf697a1353c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 0.5697 - accuracy: 0.8357 - val_loss: 0.2863 - val_accuracy: 0.9158\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 0.2215 - accuracy: 0.9313 - val_loss: 0.2400 - val_accuracy: 0.9287\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.1717 - accuracy: 0.9470 - val_loss: 0.1940 - val_accuracy: 0.9426\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.1476 - accuracy: 0.9536 - val_loss: 0.1842 - val_accuracy: 0.9413\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.1280 - accuracy: 0.9593 - val_loss: 0.1793 - val_accuracy: 0.9456\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.1118 - accuracy: 0.9646 - val_loss: 0.1358 - val_accuracy: 0.9581\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.1028 - accuracy: 0.9676 - val_loss: 0.1408 - val_accuracy: 0.9553\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 11s 47ms/step - loss: 0.0884 - accuracy: 0.9714 - val_loss: 0.1530 - val_accuracy: 0.9552\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.0855 - accuracy: 0.9721 - val_loss: 0.1147 - val_accuracy: 0.9655\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 15s 64ms/step - loss: 0.0835 - accuracy: 0.9735 - val_loss: 0.1953 - val_accuracy: 0.9462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation loss when training with only 2 hidden layers and not scaling the images seemed consistently stay much higher than on the models where the images were scaled. The validation loss on the model with 5 hidden layers was slightly better than the other model but still significantly worse than the models that had scaled images fed into them. \n",
        "\n",
        "The validation accuracy did not drop significantly for either model that did not scale the images, but it was worse so it is clear that it is beneficial to scale images that input into neural networks."
      ],
      "metadata": {
        "id": "_jr99x2J85h7"
      }
    }
  ]
}
